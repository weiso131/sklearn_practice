{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "titanic_path = \"C:/Users/weiso131/Desktop/sklearn/titanic_disaster/titanic/train.csv\"\n",
    "\n",
    "titanic_df = pd.read_csv(titanic_path)\n",
    "\n",
    "titanic_df = titanic_df.sample(n=len(titanic_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_pre_process(keep : list, df : pd.DataFrame):\n",
    "    new_df = df[keep]\n",
    "    new_df = new_df.dropna()\n",
    "    for i in new_df.index:\n",
    "        if (new_df[\"Sex\"].get(i) == \"female\"): \n",
    "            new_df.at[i ,\"Sex\"] = 0\n",
    "        else: \n",
    "            new_df.at[i ,\"Sex\"] = 1\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = [\"Survived\", \"Pclass\", \"Sex\", \"SibSp\", \"Parch\",  \"Fare\"]\n",
    "keep_Experimental = [\"Survived\", \"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Age\"]\n",
    "titanic_steady_df = data_pre_process(keep, titanic_df)\n",
    "titanic_Experimental_df = data_pre_process(keep_Experimental, titanic_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_steady = titanic_steady_df.drop(\"Survived\", axis=1).values\n",
    "y_steady = titanic_steady_df[\"Survived\"].values\n",
    "\n",
    "\n",
    "\n",
    "X_Experimental = titanic_Experimental_df.drop(\"Survived\", axis=1).values\n",
    "y_Experimental = titanic_Experimental_df[\"Survived\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_block(X : list, y : list, cut=5):\n",
    "    \"\"\"\n",
    "    return X_block, y_block\n",
    "    \"\"\"\n",
    "    n_20 = int(len(X) / cut)\n",
    "    X_block = []\n",
    "    y_block = []\n",
    "    for i in range(cut):\n",
    "        X_block.append(X[i*n_20:(i+1)*n_20])\n",
    "        y_block.append(y[i*n_20:(i+1)*n_20])\n",
    "    return X_block, y_block\n",
    "\n",
    "def assemble_block(X_block : list, y_block : list, test_i : int, cut=5):\n",
    "    \"\"\"\n",
    "    return:\n",
    "    x_train, y_train, x_test, y_test\n",
    "    \"\"\"\n",
    "    x_test, y_test = X_block[test_i], y_block[test_i]\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    for i in range(cut):\n",
    "        if (i == test_i): continue\n",
    "        x_train.extend(X_block[i])\n",
    "        y_train.extend(y_block[i])\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x_train : list, y_train : list):\n",
    "    \"\"\"\n",
    "    return rf_clf\n",
    "    \"\"\"\n",
    "    # 創建隨機森林分類器實例\n",
    "    rf_clf = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "\n",
    "    # 訓練分類器\n",
    "    rf_clf.fit(x_train, y_train)\n",
    "\n",
    "    \n",
    "\n",
    "    return rf_clf\n",
    "def test(x_train : list, y_train : list, x_test : list, y_test : list, rf_clf):\n",
    "    prediction_train = rf_clf.predict(x_train)\n",
    "    print(f\"train_acc: {accuracy_score(prediction_train, y_train)}\")\n",
    "    prediction_test = rf_clf.predict(x_test)\n",
    "    print(f\"test_acc: {accuracy_score(prediction_test, y_test)}\")\n",
    "\n",
    "    return accuracy_score(prediction_train, y_train), accuracy_score(prediction_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steady:\n",
      "train_acc: 0.9238451935081149\n",
      "test_acc: 0.8314606741573034\n",
      "Experimental:\n",
      "train_acc: 0.9358372456964006\n",
      "test_acc: 0.7746478873239436\n",
      "steady:\n",
      "train_acc: 0.9300873907615481\n",
      "test_acc: 0.7078651685393258\n",
      "Experimental:\n",
      "train_acc: 0.9342723004694836\n",
      "test_acc: 0.8028169014084507\n",
      "steady:\n",
      "train_acc: 0.9225967540574282\n",
      "test_acc: 0.797752808988764\n",
      "Experimental:\n",
      "train_acc: 0.9358372456964006\n",
      "test_acc: 0.7746478873239436\n",
      "steady:\n",
      "train_acc: 0.920099875156055\n",
      "test_acc: 0.8764044943820225\n",
      "Experimental:\n",
      "train_acc: 0.9327073552425665\n",
      "test_acc: 0.8169014084507042\n",
      "steady:\n",
      "train_acc: 0.9263420724094882\n",
      "test_acc: 0.7640449438202247\n",
      "Experimental:\n",
      "train_acc: 0.9358372456964006\n",
      "test_acc: 0.7746478873239436\n",
      "steady:\n",
      "train_acc: 0.9225967540574282\n",
      "test_acc: 0.8426966292134831\n",
      "Experimental:\n",
      "train_acc: 0.9342723004694836\n",
      "test_acc: 0.8732394366197183\n",
      "steady:\n",
      "train_acc: 0.9213483146067416\n",
      "test_acc: 0.7865168539325843\n",
      "Experimental:\n",
      "train_acc: 0.9327073552425665\n",
      "test_acc: 0.8450704225352113\n",
      "steady:\n",
      "train_acc: 0.9250936329588015\n",
      "test_acc: 0.7415730337078652\n",
      "Experimental:\n",
      "train_acc: 0.9389671361502347\n",
      "test_acc: 0.7183098591549296\n",
      "steady:\n",
      "train_acc: 0.9263420724094882\n",
      "test_acc: 0.7752808988764045\n",
      "Experimental:\n",
      "train_acc: 0.9358372456964006\n",
      "test_acc: 0.7464788732394366\n",
      "steady:\n",
      "train_acc: 0.9250936329588015\n",
      "test_acc: 0.7865168539325843\n",
      "Experimental:\n",
      "train_acc: 0.9374021909233177\n",
      "test_acc: 0.8028169014084507\n"
     ]
    }
   ],
   "source": [
    "cut = 10\n",
    "\n",
    "X_steady_block, y_steady_block = cut_block(X_steady, y_steady, cut=cut)\n",
    "X_Experimental_block, y_Experimental_block = cut_block(X_Experimental, y_Experimental, cut=cut)  \n",
    "\n",
    "\n",
    "\n",
    "avg_steady_train = 0\n",
    "avg_steady_test = 0\n",
    "avg_Experimental_train = 0\n",
    "avg_Experimental_test = 0\n",
    "\n",
    "\n",
    "\n",
    "for i in range(cut):\n",
    "    x_steady_train, y_steady_train, x_steady_test, y_steady_test = \\\n",
    "        assemble_block(X_steady_block, y_steady_block, i, cut=cut)\n",
    "    \n",
    "    x_Experimental_train, y_Experimental_train, x_Experimental_test, y_Experimental_test = \\\n",
    "        assemble_block(X_Experimental_block, y_Experimental_block, i, cut=cut)\n",
    "\n",
    "    \n",
    "    rf_clf_steady = train(x_steady_train, y_steady_train)\n",
    "    print(\"steady:\")\n",
    "    result = test(x_steady_train, y_steady_train, x_steady_test, y_steady_test, rf_clf_steady)\n",
    "\n",
    "    avg_steady_train += result[0]\n",
    "    avg_steady_test += result[1]\n",
    "\n",
    "    \n",
    "    rf_clf_Experimental = train(x_Experimental_train, y_Experimental_train)\n",
    "    print(\"Experimental:\")\n",
    "    result = test(x_Experimental_train, y_Experimental_train, x_Experimental_test, y_Experimental_test, rf_clf_Experimental)\n",
    "\n",
    "    avg_Experimental_train += result[0]\n",
    "    avg_Experimental_test += result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg steady train:0.9243445692883896, avg steady test:0.7910112359550562\n",
      "avg Experimental train:0.9353677621283257, avg Experimental test:0.7929577464788733\n"
     ]
    }
   ],
   "source": [
    "print(f\"avg steady train:{avg_steady_train / cut}, avg steady test:{avg_steady_test / cut}\")\n",
    "print(f\"avg Experimental train:{avg_Experimental_train / cut}, avg Experimental test:{avg_Experimental_test / cut}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_normal = [\"Survived\", \"Pclass\", \"Sex\", \"SibSp\", \"Parch\",  \"Fare\", \"Age\"]\n",
    "keep_lost_fare = [\"Survived\", \"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Age\"]\n",
    "keep_lost_age = [\"Survived\", \"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Fare\"]\n",
    "\n",
    "titanic_normal_df = data_pre_process(keep_normal, titanic_df)\n",
    "titanic_lost_fare_df = data_pre_process(keep_lost_fare, titanic_df)\n",
    "titanic_lost_age_df = data_pre_process(keep_lost_age, titanic_df)\n",
    "\n",
    "X_normal = titanic_normal_df.drop(\"Survived\", axis=1).values\n",
    "y_normal = titanic_normal_df[\"Survived\"].values\n",
    "\n",
    "X_lost_fare = titanic_lost_fare_df.drop(\"Survived\", axis=1).values\n",
    "y_lost_fare = titanic_lost_fare_df[\"Survived\"].values\n",
    "\n",
    "X_lost_age = titanic_lost_age_df.drop(\"Survived\", axis=1).values\n",
    "y_lost_age = titanic_lost_age_df[\"Survived\"].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_normal_model = train(X_normal, y_normal)\n",
    "final_lost_fare_model = train(X_lost_fare, y_lost_fare)\n",
    "final_lost_age_model = train(X_lost_age, y_lost_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"C:/Users/weiso131/Desktop/sklearn/titanic_disaster/titanic/test.csv\"\n",
    "\n",
    "\n",
    "keep_test_normal = [ \"Pclass\", \"Sex\", \"SibSp\", \"Parch\",  \"Fare\", \"Age\"]\n",
    "keep_test_lost_fare = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Age\"]\n",
    "keep_test_lost_age = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Fare\"]\n",
    "\n",
    "\n",
    "titanic_test_df = pd.read_csv(test_path)\n",
    "\n",
    "titanic_test_normal = data_pre_process(keep_test_normal, titanic_test_df).dropna()\n",
    "titanic_test_lost_fare = data_pre_process(keep_test_lost_fare, titanic_test_df).dropna()\n",
    "titanic_test_lost_age = data_pre_process(keep_test_lost_age, titanic_test_df).dropna()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_submission_normal = final_normal_model.predict(titanic_test_normal.values)\n",
    "prediction_submission_lost_fare = final_lost_fare_model.predict(titanic_test_lost_fare.values)\n",
    "prediction_submission_lost_age = final_lost_age_model.predict(titanic_test_lost_age.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.   0.25 0.75 0.75 0.25 0.   0.   0.   0.75 0.   0.   0.   1.   0.\n",
      " 1.   1.   0.   0.5  0.   0.25 0.   0.75 1.   0.   1.   0.   1.   0.5\n",
      " 0.75 0.   0.   0.   1.   0.   0.75 0.   0.   0.   0.   1.   0.25 1.\n",
      " 0.   1.   1.   0.   0.25 0.   1.   0.75 0.75 0.   1.   1.   0.   0.\n",
      " 0.   0.   0.   1.   0.   0.   0.   1.   0.75 1.   0.75 0.   0.   1.\n",
      " 0.75 0.   0.25 0.75 1.   0.25 0.   1.   0.   0.75 1.   0.   0.25 0.\n",
      " 0.   0.   1.   0.5  1.   1.   0.   0.   0.75 0.   0.5  0.   1.   0.5\n",
      " 0.   0.   1.   0.   0.   0.   0.5  0.   0.   0.   0.   0.   0.   0.\n",
      " 1.   1.   1.   0.   0.   1.   0.5  1.   1.   0.   1.   0.   0.   0.25\n",
      " 0.   1.   0.   0.   0.75 0.25 0.   0.   0.   0.   0.   0.   0.25 0.\n",
      " 0.   1.   0.   0.   1.   0.   0.   0.   1.   0.25 1.   0.   0.   0.75\n",
      " 0.   0.   1.   0.75 1.   1.   1.   1.   1.   0.   0.   0.25 0.25 0.\n",
      " 1.   0.25 0.   0.25 0.   0.   0.   1.   1.   0.25 1.   1.   0.   0.25\n",
      " 1.   0.   1.   0.   1.   0.   0.   0.   0.   0.   0.75 0.25 1.   0.\n",
      " 0.75 0.   0.   0.   1.   0.75 0.   1.   0.   0.   0.25 0.   1.   0.\n",
      " 0.25 0.   0.   0.25 1.   0.25 1.   0.25 1.   0.   1.   0.   1.   0.5\n",
      " 1.   1.   0.   1.   0.   0.   0.   1.   0.   0.   0.25 0.   0.25 0.5\n",
      " 1.   1.   1.   1.   0.   0.   0.   0.25 1.   0.   1.   0.   1.   0.\n",
      " 0.75 0.   0.   0.   0.   0.   1.   0.   0.   0.   1.   1.   0.   0.\n",
      " 0.   0.   0.   0.   0.25 0.   1.   1.   0.   1.   0.   0.   0.   0.\n",
      " 0.25 0.75 1.   0.   1.   0.   0.   0.25 0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   1.   0.   0.   0.   0.25 0.   0.   0.   1.   1.   1.   1.\n",
      " 0.   0.   0.   0.5  0.   0.25 1.   0.75 0.   0.   0.25 0.   0.   0.\n",
      " 0.   0.75 1.   0.   1.   0.   0.   0.   1.   0.25 0.   0.   0.25 0.\n",
      " 0.5  0.   0.   0.   0.   0.25 0.   1.   0.   1.   0.   0.25 0.   1.\n",
      " 1.   0.   0.   0.   1.   0.25 1.   0.   0.   0.25 0.   1.   1.   0.75\n",
      " 1.   0.   0.   0.25 1.   0.25 0.   1.   0.25 0.   1.   1.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.5  0.   1.   0.   0.   0.   0.   0.   1.\n",
      " 0.25 0.   0.   1.   0.   1.   0.   0.   1.   0.   1.   0.   0.   0.25\n",
      " 0.   0.   1.   0.75 1.   1.   0.   0.   1.   0.   0.   0.  ]\n",
      "[4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 1. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 1. 4.\n",
      " 4. 4. 4. 4. 4. 1. 4. 4. 4. 1. 4. 4. 1. 4. 4. 1. 4. 1. 4. 4. 4. 4. 4. 1.\n",
      " 4. 4. 4. 4. 4. 4. 1. 4. 4. 4. 1. 4. 4. 4. 4. 4. 4. 1. 4. 4. 4. 4. 4. 4.\n",
      " 4. 4. 4. 4. 1. 4. 4. 4. 4. 4. 4. 1. 1. 1. 4. 4. 1. 4. 4. 1. 4. 1. 4. 4.\n",
      " 4. 4. 4. 4. 4. 4. 1. 4. 4. 4. 4. 1. 1. 4. 4. 1. 4. 4. 4. 4. 1. 4. 4. 4.\n",
      " 4. 1. 4. 4. 1. 4. 4. 1. 4. 4. 4. 4. 1. 1. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
      " 4. 4. 1. 4. 1. 4. 4. 1. 1. 4. 4. 4. 4. 4. 4. 4. 1. 4. 4. 1. 4. 4. 4. 4.\n",
      " 1. 4. 1. 4. 4. 1. 4. 4. 4. 4. 4. 4. 4. 4. 4. 1. 4. 4. 4. 4. 1. 4. 4. 1.\n",
      " 4. 4. 4. 4. 4. 4. 4. 1. 1. 4. 4. 4. 4. 1. 4. 4. 4. 4. 4. 1. 4. 4. 4. 4.\n",
      " 1. 4. 4. 1. 4. 4. 4. 4. 4. 1. 4. 1. 4. 4. 4. 4. 4. 1. 4. 4. 4. 4. 4. 4.\n",
      " 4. 4. 4. 1. 1. 4. 4. 4. 4. 1. 4. 4. 4. 4. 4. 1. 1. 4. 4. 4. 4. 4. 4. 4.\n",
      " 4. 1. 1. 1. 1. 4. 4. 1. 4. 1. 1. 4. 4. 4. 4. 4. 4. 4. 1. 4. 4. 4. 1. 4.\n",
      " 1. 1. 1. 4. 1. 4. 4. 4. 4. 1. 4. 4. 4. 1. 4. 4. 1. 4. 4. 4. 4. 4. 4. 4.\n",
      " 1. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 1. 4. 4. 4.\n",
      " 4. 4. 4. 1. 4. 4. 1. 4. 1. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 1. 1. 4.\n",
      " 4. 4. 4. 4. 4. 1. 1. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 1. 4. 1. 4.\n",
      " 1. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
      " 1. 4. 1. 4. 4. 1. 4. 4. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "all_prediction = np.zeros(418)\n",
    "all_predict_count = np.zeros(418)\n",
    "\n",
    "for i in range(len(titanic_test_normal)):\n",
    "    index = titanic_test_normal.index[i]\n",
    "    all_prediction[index] += prediction_submission_normal[i] * 2\n",
    "    all_predict_count[index] += 2\n",
    "\n",
    "for i in range(len(titanic_test_lost_fare)):\n",
    "    index = titanic_test_lost_fare.index[i]\n",
    "    all_prediction[index] += prediction_submission_lost_fare[i]\n",
    "    all_predict_count[index] += 1\n",
    "\n",
    "for i in range(len(titanic_test_lost_age)):\n",
    "    index = titanic_test_lost_age.index[i]\n",
    "    all_prediction[index] += prediction_submission_lost_age[i]\n",
    "    all_predict_count[index] += 1\n",
    "\n",
    "all_prediction = all_prediction / all_predict_count\n",
    "\n",
    "print(all_prediction)\n",
    "print(all_predict_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_path = \"C:/Users/weiso131/Desktop/sklearn/titanic_disaster/titanic/submission.csv\"\n",
    "\n",
    "submission_df = pd.read_csv(submission_path)\n",
    "\n",
    "for i in range(len(submission_df)):\n",
    "    index = submission_df.index[i]\n",
    "    \n",
    "    if (all_prediction[i] < 0.5): all_prediction[i] = 0\n",
    "    else: all_prediction[i] = 1\n",
    "\n",
    "    submission_df.at[index, \"Survived\"] = int(all_prediction[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived\n",
      "0            892         0\n",
      "1            893         0\n",
      "2            894         1\n",
      "3            895         1\n",
      "4            896         0\n",
      "..           ...       ...\n",
      "413         1305         0\n",
      "414         1306         1\n",
      "415         1307         0\n",
      "416         1308         0\n",
      "417         1309         0\n",
      "\n",
      "[418 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(submission_df)\n",
    "submission_df.to_csv(\"submission_weiso.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
